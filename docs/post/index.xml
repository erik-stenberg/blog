<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on erst</title>
    <link>/post/</link>
    <description>Recent content in Posts on erst</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 11 Mar 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Python in knitr</title>
      <link>/post/python-test/</link>
      <pubDate>Sun, 11 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/python-test/</guid>
      <description>In this post I’ll try to render Python with blogdown, which I haven’t done before. Hopefully it’ll work just as smooth as Jupyter notebook. By default, blogdown uses the System installed version of Python, and to force blogdown to use Python 3, which I want, I need to include
knitr::opts_chunk$set(engine.path = &amp;quot;/Users/erik/anaconda/bin/python&amp;quot;) I will use Monte Carlo integration to approximate the integral
\[E_f(g(p)) = P(D|M_k) = \int f(\textbf{p})g(\textbf{p})d\textbf{p}\] using the fact that we can simulate \[p_1,.</description>
    </item>
    
    <item>
      <title>Classification with sparklyr</title>
      <link>/post/classification-with-sparklyr/</link>
      <pubDate>Sat, 10 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/classification-with-sparklyr/</guid>
      <description>In this post I will use fairly new R package sparklyr which allows you to connect from Spark with R to use Spark’s machine learning library. All with a complete dplyr backend. To connect to a local instance of Spark, you first need to spark_install and then connect to that instance with spark_connect where the master argument should be “local”
I will use the flights data from nycflights13 package to try to predict flights that will be delayed.</description>
    </item>
    
    <item>
      <title>Comparison of different classification methods</title>
      <link>/post/comparison-of-different-classification-methods/</link>
      <pubDate>Sat, 10 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/comparison-of-different-classification-methods/</guid>
      <description>In this post I’ll be comparing a set of classification algorithms to perform a rather simple task, classify emails as either spam or not spam. To begin with, I’ll look at logit and probit models.
The data The original dataset can be found here and was published by UCI Machine Learning Repository. The data consist 4601 emails of which 1813 are spam. The data does not actually consist of emails, but rather 57 predictor variables, which can be divided into three types.</description>
    </item>
    
    <item>
      <title>Migration Data Visualisation</title>
      <link>/post/immigration-data/</link>
      <pubDate>Sat, 10 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/immigration-data/</guid>
      <description>In this post I will be visualizing the migration pattern of the US with data from 2012 using a chord diagram from the chorddiag package which in turn is using the JavaScript visualization library D3. The data I’m going to use are stored in two files.
library(readr) library(tidyverse) dat &amp;lt;- read_csv(&amp;quot;migration2016.csv&amp;quot;) states &amp;lt;- read_csv(&amp;quot;states_chord.csv&amp;quot;) head(dat[1:5],5) ## # A tibble: 5 x 5 ## To Alabama Alaska Arizona Arkansas ## &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; ## 1 Alabama NA 576 1022 495 ## 2 Alaska 423 NA 1176 65 ## 3 Arizona 894 1946 NA 1205 ## 4 Arkansas 2057 103 836 NA ## 5 California 3045 4206 33757 4282 We can for example see that 423 people moved from Alabama to Alaska.</description>
    </item>
    
    <item>
      <title>Shakespeare</title>
      <link>/post/shakespeare/</link>
      <pubDate>Thu, 08 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/shakespeare/</guid>
      <description>library(readr) suppressMessages(Shakespeare &amp;lt;- read_csv(&amp;quot;Shakespeare.csv&amp;quot;)) library(treemap) treemap(Shakespeare, index=(c(&amp;quot;Play_ID&amp;quot;)), vSize=&amp;quot;nLines&amp;quot;) library(dplyr) Shakespeare %&amp;gt;% group_by(Play_ID) %&amp;gt;% summarise(s = sum(nLines)) %&amp;gt;% arrange(desc(s)) ## # A tibble: 17 x 2 ## Play_ID s ## &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt; ## 1 The Tragedy Of Othello 1130 ## 2 The Tragedy of Hamlet, Prince of Denmark 1046 ## 3 Antony And Cleopatra 1016 ## 4 King Lear 930 ## 5 Coriolanus 828 ## 6 Taming Of The Shrew 795 ## 7 As You Like It 793 ## 8 Cymbeline 745 ## 9 Romeo And Juliet 695 ## 10 Julius Caesar 676 ## 11 Merchant Of Venice 630 ## 12 The Tempest 628 ## 13 Henry VIII 596 ## 14 Comedy Of Errors 578 ## 15 History Of King John 527 ## 16 Midsummer Night&amp;#39;s Dream 498 ## 17 The Tragedy Of Macbeth 491 library(sunburstR) str2 = Shakespeare %&amp;gt;% mutate(str = paste0(&amp;quot;Type:&amp;quot;,Type,&amp;quot;-&amp;quot;,&amp;quot;Play:&amp;quot;,Play_ID,&amp;quot;-&amp;quot;,&amp;quot;Character:&amp;quot;,Character_ID)) %&amp;gt;% select(str, nLines) sunburst(str2)      Legend     {&#34;</description>
    </item>
    
    <item>
      <title>Shiny App: Airline Routes</title>
      <link>/post/flights/</link>
      <pubDate>Thu, 08 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/flights/</guid>
      <description>In this post I am going to create a simple Shiny app that will show different airlines and their routes. First of all I will pick three airlines and create a plot, and from there incoroprate it into a Shiny app with a few inputs. The data are from openflights.org. The package I will use for the visualization is threejs which is a package part of the three.</description>
    </item>
    
  </channel>
</rss>